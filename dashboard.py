import os
import pandas as pd
import streamlit as st
import plotly.express as px
from dashboard_table_generator import generate_table_multiple_years, generate_table_single_year
from dashboard_downloads import download_table_as_excel, download_detailed_list
from dashboard_utils import render_table
from sklearn.linear_model import LinearRegression
import numpy as np
from prophet import Prophet
import plotly.graph_objects as go
from io import BytesIO

# M칩dulos habilitados
modules = {
    'CCM': '游늵 CCM',
    'PRR': '游늳 PRR',
    'CCM-ESP': '游늴 CCM-ESP',
    'CCM-LEY': '游늶 CCM-LEY',  # A침adido CCM-LEY
    'SOL': '游늭 SOL',
}

st.title("Gesti칩n de Expedientes")

@st.cache_data
def load_consolidated_cached(module_name):
    folder = f"descargas/{module_name}"
    for file in os.listdir(folder):
        if file.startswith(f"Consolidado_{module_name}_CRUZADO") and file.endswith(".xlsx"):
            file_path = os.path.join(folder, file)
            data = pd.read_excel(file_path)
            data['Anio'] = data['Anio'].astype(int)
            data['Mes'] = data['Mes'].astype(int)
            data['FechaExpendiente'] = pd.to_datetime(data['FechaExpendiente'])  # Aseguramos formato de fecha
            return data
    return None

# L칩gica para CCM-LEY usando CCM y excluyendo CCM-ESP
def load_ccm_ley_data():
    # Cargar datos de CCM y CCM-ESP
    ccm_data = load_consolidated_cached('CCM')
    ccm_esp_data = load_consolidated_cached('CCM-ESP')
    
    if ccm_data is not None and ccm_esp_data is not None:
        # Mostrar estad칤sticas iniciales
        
        # Filtrar CCM-LEY: registros de CCM que no est치n en CCM-ESP
        ccm_ley_data = ccm_data[~ccm_data['NumeroTramite'].isin(ccm_esp_data['NumeroTramite'])]

        # Verificar estad칤sticas despu칠s de la exclusi칩n
        
        # Validar columnas necesarias
        required_columns = ['FechaExpendiente', 'FechaPre']
        for col in required_columns:
            if col not in ccm_ley_data.columns:
                st.error(f"Falta la columna requerida: {col}")
                return None

        # Asegurarnos de que las fechas se interpreten correctamente
        try:
            ccm_ley_data['FechaExpendiente'] = pd.to_datetime(ccm_ley_data['FechaExpendiente'], format='%d/%m/%Y', errors='coerce')
            ccm_ley_data['FechaPre'] = pd.to_datetime(ccm_ley_data['FechaPre'], format='%d/%m/%Y', errors='coerce')
        except Exception as e:
            st.error(f"Error al convertir las fechas: {e}")
            return None

        # Identificar registros con fechas inconsistentes
        invalid_dates = ccm_ley_data[ccm_ley_data['FechaExpendiente'] > ccm_ley_data['FechaPre']]

        # Descargar registros con fechas inconsistentes
        if not invalid_dates.empty:
            st.subheader("Descarga de registros con fechas inconsistentes")
            # Crear un buffer de memoria para almacenar el Excel
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                invalid_dates.to_excel(writer, index=False, sheet_name='Fechas Inconsistentes')
            output.seek(0)  # Volver al inicio del buffer

            # Bot칩n de descarga
            st.download_button(
                label="Descargar registros inconsistentes",
                data=output,
                file_name="registros_inconsistentes.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        
        return ccm_ley_data
    
    st.error("No se pudo cargar la informaci칩n de CCM o CCM-ESP.")
    return None


# Men칰 de navegaci칩n para m칩dulos
selected_module = st.sidebar.radio(
    "Selecciona un m칩dulo",
    options=list(modules.keys()),
    format_func=lambda x: modules[x]
)

# Cargar datos del m칩dulo
if selected_module == 'CCM-LEY':
    data = load_ccm_ley_data()
else:
    data = load_consolidated_cached(selected_module)

if data is None:
    st.error("No se encontr칩 el archivo consolidado para este m칩dulo.")
else:
    # Crear pesta침as para el m칩dulo
    tabs = st.tabs(["Dashboard de Pendientes", "Ingreso de Expedientes", "Cierre de Expedientes","Ranking de Evaluadores"])
    
# Listas de evaluadores inactivos por m칩dulo
inactive_evaluators = {
    "CCM": [
        "Mauricio Romero, Hugo",
        "Ugarte S치nchez, Paulo C칠sar",
        "Santiba침ez Chafalote, Lila Mariella",
        "Quispe Orosco, Karina Wendy",
        "Miranda Avila, Marco Antonio",
        "Aponte Sanchez, Paola Lita",
        "Orcada Herrera, Javier Eduardo",
        "Gomez Vera, Marcos Alberto"
    ],
    "PRR": [
        "Pozo Ferro, Sonia Leonor",
        "Bautista Lopez, Diana Carolina",
        "Infantes Panduro, Jheyson",
        "Vizcardo Ordo침ez, Fiorella Carola",
        "Ponce Malpartida, Miguel",
        "Valdez Gallo, Cynthia Andrea",
        "Hurtado Lago Briyan Deivi",
        "Diaz Amaya, Esthefany Lisset",
        "Santiba침ez Chafalote, Lila Mariella",
        "Pumallanque Ramirez, Mariela",
        "Valera Gaviria, Jessica Valeria",
        "V치squez Fernandez, Anthony Piere"
    ]
}

# Pesta침a 1: Dashboard de Pendientes
with tabs[0]:
    st.header("Dashboard de Pendientes")
    
    # Filtrar los evaluadores inactivos del m칩dulo seleccionado
    module_inactive_evaluators = inactive_evaluators.get(selected_module, [])

    # Selecci칩n de a침os
    selected_years = st.multiselect("Selecciona los A침os", sorted(data['Anio'].unique()))
    
    # Selecci칩n de evaluadores con separaci칩n de activos e inactivos
    evaluators = sorted(data['EVALASIGN'].dropna().unique())
    active_evaluators = [e for e in evaluators if e not in module_inactive_evaluators]
    inactive_evaluators_in_data = [e for e in evaluators if e in module_inactive_evaluators]

    st.subheader("Evaluadores Activos")
    selected_active_evaluators = []
    with st.expander("Filtro de Evaluadores Activos (Clic para expandir)", expanded=True):
        select_all_active = st.checkbox("Seleccionar Todos (Activos)", value=True, key="active")
        for evaluator in active_evaluators:
            if select_all_active or st.checkbox(evaluator, value=True, key=f"checkbox_active_{evaluator}"):
                selected_active_evaluators.append(evaluator)

    st.subheader("Evaluadores Inactivos")
    selected_inactive_evaluators = []
    with st.expander("Filtro de Evaluadores Inactivos (Clic para expandir)", expanded=False):
        select_all_inactive = st.checkbox("Seleccionar Todos (Inactivos)", value=False, key="inactive")
        for evaluator in inactive_evaluators_in_data:
            if select_all_inactive or st.checkbox(evaluator, value=False, key=f"checkbox_inactive_{evaluator}"):
                selected_inactive_evaluators.append(evaluator)

    # Combinar los evaluadores seleccionados
    selected_evaluators = selected_active_evaluators + selected_inactive_evaluators

    # Mostrar tabla y descargas si se seleccionan a침os
    if selected_years:
        # Filtrar solo los pendientes (Evaluado == NO)
        filtered_data = data[data['Evaluado'] == 'NO']

        if len(selected_years) > 1:
            # Generar tabla para m칰ltiples a침os
            table = generate_table_multiple_years(filtered_data, selected_years, selected_evaluators)
            total_pendientes = table['Total'].sum()
            st.metric("Total de Expedientes Pendientes", total_pendientes)
            render_table(table, "Pendientes por Evaluador (Varios A침os)")
            
            # Descarga como Excel
            excel_buf = download_table_as_excel(table, "Pendientes Varios A침os")
            st.download_button(
                "Descargar como Excel",
                excel_buf,
                file_name="pendientes_varios_anos.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            # Generar tabla para un solo a침o
            table = generate_table_single_year(filtered_data, selected_years[0], selected_evaluators)
            total_pendientes = table['Total'].sum()
            st.metric("Total de Expedientes Pendientes", total_pendientes)
            render_table(table, f"Pendientes por Evaluador ({selected_years[0]})")
            
            # Descarga como Excel
            excel_buf = download_table_as_excel(table, f"Pendientes A침o {selected_years[0]}")
            st.download_button(
                "Descargar como Excel",
                excel_buf,
                file_name=f"pendientes_{selected_years[0]}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    
        # Descarga Detallada
        filters = {
            'Anio': selected_years if selected_years else None,
            'EVALASIGN': selected_evaluators if selected_evaluators else None
        }
        detailed_buf = download_detailed_list(filtered_data, filters)
        st.download_button(
            "Descargar Detallado (Pendientes - Todos los Filtros)",
            detailed_buf,
            file_name="pendientes_detallado_filtrado.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
    else:
        st.warning("Por favor selecciona al menos un a침o.")

# Pesta침a 2: Ingreso de Expedientes
with tabs[1]:
    st.header("Ingreso de Expedientes")
    st.info("Gr치ficos de tendencias y predicciones sobre ingresos de expedientes.")

    # Gr치fico 1: Ingresos diarios durante los 칰ltimos 45 d칤as con tendencia y predicci칩n
    st.subheader("Evoluci칩n de Ingresos Diarios (칔ltimos 45 D칤as)")
    
    # Filtrar los 칰ltimos 45 d칤as
    last_45_days_data = data[data['FechaExpendiente'] >= (pd.Timestamp.now() - pd.DateOffset(days=45))]
    daily_counts_45 = last_45_days_data.groupby(last_45_days_data['FechaExpendiente'].dt.date).size().reset_index(name='Ingresos')
    daily_counts_45.rename(columns={'index': 'FechaExpendiente'}, inplace=True)
    daily_counts_45['FechaExpendiente'] = pd.to_datetime(daily_counts_45['FechaExpendiente'])
    
    # Crear l칤nea de tendencia con regresi칩n lineal
    X_days_45 = np.arange(len(daily_counts_45)).reshape(-1, 1)
    y_days_45 = daily_counts_45['Ingresos']
    model_days_45 = LinearRegression()
    model_days_45.fit(X_days_45, y_days_45)
    trend_days_45 = model_days_45.predict(X_days_45)
    
    # Predicci칩n para los pr칩ximos 7 d칤as
    future_days_45 = np.arange(len(daily_counts_45) + 7).reshape(-1, 1)
    future_predictions_45 = model_days_45.predict(future_days_45)
    future_dates_45 = pd.date_range(start=daily_counts_45['FechaExpendiente'].iloc[-1], periods=8, freq='D')[1:]
    
    # Combinar datos existentes y predicciones
    pred_df_45 = pd.DataFrame({'FechaExpendiente': future_dates_45, 'Ingresos': future_predictions_45[-7:]})
    combined_df_45 = pd.concat([daily_counts_45, pred_df_45], ignore_index=True)

    # Graficar
    fig_daily_45 = px.line(daily_counts_45, x='FechaExpendiente', y='Ingresos', title="Ingresos Diarios (칔ltimos 45 D칤as)", markers=True)
    fig_daily_45.add_scatter(x=daily_counts_45['FechaExpendiente'], y=trend_days_45, mode='lines', line=dict(color='red', dash='dot'), name='Tendencia')
    fig_daily_45.add_scatter(x=future_dates_45, y=future_predictions_45[-7:], mode='lines+markers', line=dict(color='green', dash='dash'), name='Predicci칩n (Pr칩ximos 7 d칤as)')
    st.plotly_chart(fig_daily_45)
    
    # Explicaci칩n del Gr치fico
    st.write("""
    **Interpretaci칩n del Gr치fico:**
    - Este gr치fico muestra los ingresos diarios de expedientes en los 칰ltimos 45 d칤as.
    - La l칤nea roja punteada indica la tendencia general de los ingresos diarios.
    - La l칤nea verde discontinua proyecta los ingresos diarios para los pr칩ximos 7 d칤as.
    """)

    # Gr치fico 2: Pron칩stico de ingresos diarios con Prophet
    st.subheader("Pron칩stico de Ingresos Diarios")

    # Preparar los datos hist칩ricos completos para Prophet
    historical_data = data[['FechaExpendiente']].copy()
    historical_data['ds'] = historical_data['FechaExpendiente']
    daily_counts = historical_data.groupby(historical_data['ds'].dt.date).size().reset_index(name='y')
    daily_counts.rename(columns={'index': 'ds'}, inplace=True)
    daily_counts['ds'] = pd.to_datetime(daily_counts['ds'])  # Aseguramos el formato de fecha
    daily_counts = daily_counts[['ds', 'y']]  # Prophet requiere columnas ds (fecha) y y (valor)

    # Crear modelo Prophet
    model = Prophet(daily_seasonality=True, yearly_seasonality=True)
    model.fit(daily_counts)

    # Generar pron칩stico para los pr칩ximos 30 d칤as
    future_dates = model.make_future_dataframe(periods=30)
    forecast = model.predict(future_dates)

    # Graficar pron칩stico optimizado
    st.subheader("Pron칩stico de Ingresos Diarios (Optimizado para los Pr칩ximos 30 D칤as)")

    # Filtrar 칰ltimos 60 d칤as hist칩ricos + pr칩ximos 30 d칤as pronosticados
    forecast_focus = forecast[(forecast['ds'] >= (pd.Timestamp.now() - pd.DateOffset(days=60)))]

    fig_daily_optimized = px.line(
        forecast_focus, 
        x='ds', 
        y='yhat', 
        title="Pron칩stico de Ingresos Diarios (30 d칤as)", 
        labels={'ds': 'Fecha', 'yhat': 'Ingresos Estimados'}
    )

    # Resaltar la l칤nea central del pron칩stico
    fig_daily_optimized.add_scatter(
        x=forecast_focus['ds'], 
        y=forecast_focus['yhat'], 
        mode='lines', 
        line=dict(color='green', width=3), 
        name='Pron칩stico'
    )

    # L칤mites con menos opacidad
    fig_daily_optimized.add_scatter(
        x=forecast_focus['ds'], 
        y=forecast_focus['yhat_lower'], 
        mode='lines', 
        line=dict(color='blue', dash='dot', width=1), 
        name='L칤mite Inferior'
    )

    fig_daily_optimized.add_scatter(
        x=forecast_focus['ds'], 
        y=forecast_focus['yhat_upper'], 
        mode='lines', 
        line=dict(color='blue', dash='dot', width=1), 
        name='L칤mite Superior'
    )

    st.plotly_chart(fig_daily_optimized)

    # Explicaci칩n del Pron칩stico
    st.write("""
    **Interpretaci칩n del Pron칩stico:**
    - Este gr치fico muestra la tendencia diaria de los ingresos de expedientes basada en datos hist칩ricos desde 2018.
    - La l칤nea verde representa el pron칩stico central (promedio estimado) para los pr칩ximos 30 d칤as.
    - Las l칤neas azules punteadas indican los l칤mites de confianza superior e inferior, lo que significa que los valores reales podr칤an variar dentro de este rango.
    - Si la l칤nea de predicci칩n est치 subiendo, se espera un aumento en los ingresos diarios. Si est치 bajando, podr칤a haber una disminuci칩n.
    """)

    # Resumen Estad칤stico del Pron칩stico
    avg_prediction = forecast['yhat'][-30:].mean()
    st.write(f"""
    En promedio, se estima que el ingreso diario de expedientes para los pr칩ximos 30 d칤as ser치 de aproximadamente **{avg_prediction:.2f} expedientes por d칤a**.
    """)

# Pesta침a 3: Cierre de Expedientes
with tabs[2]:
    st.header("Cierre de Expedientes")

    # Asegurarnos de que 'FechaExpendiente' y 'FechaPre' est칠n en formato datetime
    data['FechaExpendiente'] = pd.to_datetime(data['FechaExpendiente'], errors='coerce')
    data['FechaPre'] = pd.to_datetime(data['FechaPre'], errors='coerce')

    # Filtrar los 칰ltimos 15 d칤as para la matriz de cierre
    last_15_days = pd.Timestamp.now() - pd.DateOffset(days=15)
    cierre_data_last_15 = data[data['FechaPre'] >= last_15_days].copy()

    # Agrupar por evaluador y fecha de cierre
    cierre_matrix = cierre_data_last_15.groupby(['EVALASIGN', cierre_data_last_15['FechaPre'].dt.date]).size().unstack(fill_value=0)

    # Limitar a los 칰ltimos 15 d칤as
    cierre_matrix = cierre_matrix.loc[:, cierre_matrix.columns[-15:]]

    # Renombrar las columnas de fecha a formato dd/mm
    cierre_matrix.columns = [col.strftime('%d/%m') for col in cierre_matrix.columns]

    # Calcular tendencia (aumenta, disminuye, mantiene), ignorando ceros
    tendencias = {}
    for evaluador in cierre_matrix.index:
        series = cierre_matrix.loc[evaluador]
        # Filtrar valores diferentes de cero
        series_nonzero = series[series > 0]
        if series_nonzero.diff().sum() > 0:
            tendencia = "拘勇"
        elif series_nonzero.diff().sum() < 0:
            tendencia = "拘勇"
        else:
            tendencia = "俱뫮잺"
        tendencias[evaluador] = tendencia

    # Agregar la tendencia al final de la matriz
    cierre_matrix['Tendencia'] = cierre_matrix.index.map(tendencias)

    # Calcular el promedio de cierre por evaluador
    cierre_matrix['Promedio'] = cierre_matrix.drop(columns=['Tendencia']).mean(axis=1)

    # Ordenar la matriz por promedio de mayor a menor
    cierre_matrix = cierre_matrix.sort_values(by='Promedio', ascending=False)

    # Mostrar la matriz en Streamlit
    st.subheader("Matriz de Cierre de Expedientes (칔ltimos 15 D칤as)")
    st.dataframe(cierre_matrix)

    # Filtro de per칤odo din치mico
    st.subheader("Selecciona el Per칤odo de An치lisis")
    period_options = ["칔ltimos 30 d칤as", "칔ltimos 3 meses", "칔ltimos 6 meses"]
    selected_period = st.radio("Per칤odo", period_options, index=1)  # Por defecto, selecciona "칔ltimos 3 meses"

    # Filtrar datos seg칰n el per칤odo seleccionado
    if selected_period == "칔ltimos 30 d칤as":
        start_date = pd.Timestamp.now() - pd.DateOffset(days=30)
    elif selected_period == "칔ltimos 3 meses":
        start_date = pd.Timestamp.now() - pd.DateOffset(months=3)
    elif selected_period == "칔ltimos 6 meses":
        start_date = pd.Timestamp.now() - pd.DateOffset(months=6)

    cierre_data = data[data['FechaExpendiente'] >= start_date].copy()

    # Validar fechas: excluir registros con inconsistencias
    valid_cierre_data = cierre_data[cierre_data['FechaPre'] >= cierre_data['FechaExpendiente']]
    invalid_cierre_data = cierre_data[cierre_data['FechaPre'] < cierre_data['FechaExpendiente']]

    # Mostrar advertencia sobre registros excluidos
    if len(invalid_cierre_data) > 0:
        st.warning(f"Se excluyeron {len(invalid_cierre_data)} registros con fechas inconsistentes.")
        
        # Bot칩n para descargar los registros inconsistentes
        st.subheader("Descargar registros con fechas inconsistentes")
        from io import BytesIO
        output = BytesIO()
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            invalid_cierre_data.to_excel(writer, index=False, sheet_name='Fechas Inconsistentes')
        output.seek(0)  # Volver al inicio del buffer

        st.download_button(
            label="Descargar registros inconsistentes",
            data=output,
            file_name="fechas_inconsistentes.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

    # Reemplazar el cierre_data con los datos v치lidos
    cierre_data = valid_cierre_data

    # Calcular el tiempo promedio de cierre por evaluador
    cierre_data['TiempoCierre'] = (cierre_data['FechaPre'] - cierre_data['FechaExpendiente']).dt.days
    tiempo_promedio_general = cierre_data['TiempoCierre'].mean()

    # Agrupar por evaluador para calcular el promedio de tiempo de cierre
    tiempo_promedio_por_evaluador = cierre_data.groupby('EVALASIGN')['TiempoCierre'].mean().reset_index()
    tiempo_promedio_por_evaluador.rename(columns={'TiempoCierre': 'PromedioD칤asCierre'}, inplace=True)
    tiempo_promedio_por_evaluador = tiempo_promedio_por_evaluador.sort_values(by='PromedioD칤asCierre', ascending=False)

    # Mostrar el tiempo promedio general
    st.metric(f"Tiempo Promedio General de Cierre ({selected_period})", f"{tiempo_promedio_general:.2f} d칤as")

    # Mostrar tabla de tiempos promedio por evaluador
    st.subheader(f"Tiempos Promedio de Cierre por Evaluador ({selected_period})")
    st.dataframe(tiempo_promedio_por_evaluador[['EVALASIGN', 'PromedioD칤asCierre']].reset_index(drop=True))  # Eliminar 칤ndice

    # Distribuci칩n de cierres por tiempo en d칤as con 10 categor칤as fijas
    bins = [1, 3, 6, 9, 12, 15, 18, 21, 24, 28, float('inf')]  # Categor칤as fijas
    labels = [
        "1-3 d칤as", "4-6 d칤as", "7-9 d칤as", "10-12 d칤as",
        "13-15 d칤as", "16-18 d칤as", "19-21 d칤as", "22-24 d칤as",
        "25-28 d칤as", "28+ d칤as"
    ]
    cierre_data['Categor칤aTiempo'] = pd.cut(
        cierre_data['TiempoCierre'],
        bins=bins,
        labels=labels,
        include_lowest=True
    )

    cierre_categor칤as = cierre_data['Categor칤aTiempo'].value_counts(normalize=True).sort_index() * 100

    st.subheader(f"Distribuci칩n de Cierres por Tiempo ({selected_period})")
    fig_categor칤as = px.bar(
        cierre_categor칤as,
        x=cierre_categor칤as.index,
        y=cierre_categor칤as.values,
        title=f"Cierres de Expedientes por Tiempo ({selected_period})",
        labels={'x': "Categor칤a de Tiempo", 'y': "Porcentaje de Expedientes"},
        text_auto=True
    )
    st.plotly_chart(fig_categor칤as)

    st.write("""
    **Interpretaci칩n del Indicador:**
    - El gr치fico muestra la distribuci칩n porcentual de los expedientes seg칰n el tiempo tomado para su cierre.
    - Las categor칤as ayudan a identificar patrones de eficiencia en los cierres.
    """)
