import os
import pandas as pd
import streamlit as st
import plotly.express as px
from dashboard_table_generator import generate_table_multiple_years, generate_table_single_year
from dashboard_downloads import download_table_as_excel, download_detailed_list
from dashboard_utils import render_table
from sklearn.linear_model import LinearRegression
import numpy as np
from prophet import Prophet
import plotly.graph_objects as go

# M칩dulos habilitados
modules = {
    'CCM': '游늵 CCM',
    'PRR': '游늳 PRR',
    'CCM-ESP': '游늴 CCM-ESP',
    'CCM-LEY': '游늶 CCM-LEY',  # A침adido CCM-LEY
    'SOL': '游늭 SOL',
}

st.title("Gesti칩n de Expedientes")

@st.cache_data
def load_consolidated_cached(module_name):
    folder = f"descargas/{module_name}"
    for file in os.listdir(folder):
        if file.startswith(f"Consolidado_{module_name}_CRUZADO") and file.endswith(".xlsx"):
            file_path = os.path.join(folder, file)
            data = pd.read_excel(file_path)
            data['Anio'] = data['Anio'].astype(int)
            data['Mes'] = data['Mes'].astype(int)
            data['FechaExpendiente'] = pd.to_datetime(data['FechaExpendiente'])  # Aseguramos formato de fecha
            return data
    return None

# L칩gica para CCM-LEY usando CCM y excluyendo CCM-ESP
def load_ccm_ley_data():
    # Cargar datos de CCM y CCM-ESP
    ccm_data = load_consolidated_cached('CCM')
    ccm_esp_data = load_consolidated_cached('CCM-ESP')
    
    if ccm_data is not None and ccm_esp_data is not None:
        # Filtrar CCM-LEY: registros de CCM que no est치n en CCM-ESP
        ccm_ley_data = ccm_data[~ccm_data['NumeroTramite'].isin(ccm_esp_data['NumeroTramite'])]
        
        return ccm_ley_data
    
    st.error("No se pudo cargar la informaci칩n de CCM o CCM-ESP.")
    return None


# Men칰 de navegaci칩n para m칩dulos
selected_module = st.sidebar.radio(
    "Selecciona un m칩dulo",
    options=list(modules.keys()),
    format_func=lambda x: modules[x]
)

# Cargar datos del m칩dulo
if selected_module == 'CCM-LEY':
    data = load_ccm_ley_data()
else:
    data = load_consolidated_cached(selected_module)

if data is None:
    st.error("No se encontr칩 el archivo consolidado para este m칩dulo.")
else:
    # Crear pesta침as para el m칩dulo
    tabs = st.tabs(["Dashboard de Pendientes", "Ingreso de Expedientes", "Cierre de Expedientes"])
    
    # Pesta침a 1: Dashboard de Pendientes
    with tabs[0]:
        st.header("Dashboard de Pendientes")
        
        # Selecci칩n de a침os
        selected_years = st.multiselect("Selecciona los A침os", sorted(data['Anio'].unique()))
        
        # Selecci칩n de evaluadores con checkboxes compactos
        evaluators = sorted(data['EVALASIGN'].dropna().unique())
        st.subheader("Selecciona los Evaluadores")
        selected_evaluators = []
        with st.expander("Filtro de Evaluadores (Clic para expandir)", expanded=True):
            select_all = st.checkbox("Seleccionar Todos", value=True)
            for evaluator in evaluators:
                if select_all or st.checkbox(evaluator, value=True, key=f"checkbox_{evaluator}"):
                    selected_evaluators.append(evaluator)

        # Mostrar tabla y descargas si se seleccionan a침os
        if selected_years:
            # Filtrar solo los pendientes (Evaluado == NO)
            filtered_data = data[data['Evaluado'] == 'NO']

            if len(selected_years) > 1:
                # Generar tabla para m칰ltiples a침os
                table = generate_table_multiple_years(filtered_data, selected_years, selected_evaluators)
                total_pendientes = table['Total'].sum()
                st.metric("Total de Expedientes Pendientes", total_pendientes)
                render_table(table, "Pendientes por Evaluador (Varios A침os)")
                
                # Descarga como Excel
                excel_buf = download_table_as_excel(table, "Pendientes Varios A침os")
                st.download_button(
                    "Descargar como Excel",
                    excel_buf,
                    file_name="pendientes_varios_anos.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
            else:
                # Generar tabla para un solo a침o
                table = generate_table_single_year(filtered_data, selected_years[0], selected_evaluators)
                total_pendientes = table['Total'].sum()
                st.metric("Total de Expedientes Pendientes", total_pendientes)
                render_table(table, f"Pendientes por Evaluador ({selected_years[0]})")
                
                # Descarga como Excel
                excel_buf = download_table_as_excel(table, f"Pendientes A침o {selected_years[0]}")
                st.download_button(
                    "Descargar como Excel",
                    excel_buf,
                    file_name=f"pendientes_{selected_years[0]}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
        
            # Descarga Detallada
            filters = {
                'Anio': selected_years if selected_years else None,
                'EVALASIGN': selected_evaluators if selected_evaluators else None
            }
            detailed_buf = download_detailed_list(filtered_data, filters)
            st.download_button(
                "Descargar Detallado (Pendientes - Todos los Filtros)",
                detailed_buf,
                file_name="pendientes_detallado_filtrado.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        else:
            st.warning("Por favor selecciona al menos un a침o.")

# Pesta침a 2: Ingreso de Expedientes
with tabs[1]:
    st.header("Ingreso de Expedientes")
    st.info("Gr치ficos de tendencias y predicciones sobre ingresos de expedientes.")

    # Gr치fico 1: Ingresos diarios durante los 칰ltimos 45 d칤as con tendencia y predicci칩n
    st.subheader("Evoluci칩n de Ingresos Diarios (칔ltimos 45 D칤as)")
    
    # Filtrar los 칰ltimos 45 d칤as
    last_45_days_data = data[data['FechaExpendiente'] >= (pd.Timestamp.now() - pd.DateOffset(days=45))]
    daily_counts_45 = last_45_days_data.groupby(last_45_days_data['FechaExpendiente'].dt.date).size().reset_index(name='Ingresos')
    daily_counts_45.rename(columns={'index': 'FechaExpendiente'}, inplace=True)
    daily_counts_45['FechaExpendiente'] = pd.to_datetime(daily_counts_45['FechaExpendiente'])
    
    # Crear l칤nea de tendencia con regresi칩n lineal
    X_days_45 = np.arange(len(daily_counts_45)).reshape(-1, 1)
    y_days_45 = daily_counts_45['Ingresos']
    model_days_45 = LinearRegression()
    model_days_45.fit(X_days_45, y_days_45)
    trend_days_45 = model_days_45.predict(X_days_45)
    
    # Predicci칩n para los pr칩ximos 7 d칤as
    future_days_45 = np.arange(len(daily_counts_45) + 7).reshape(-1, 1)
    future_predictions_45 = model_days_45.predict(future_days_45)
    future_dates_45 = pd.date_range(start=daily_counts_45['FechaExpendiente'].iloc[-1], periods=8, freq='D')[1:]
    
    # Combinar datos existentes y predicciones
    pred_df_45 = pd.DataFrame({'FechaExpendiente': future_dates_45, 'Ingresos': future_predictions_45[-7:]})
    combined_df_45 = pd.concat([daily_counts_45, pred_df_45], ignore_index=True)

    # Graficar
    fig_daily_45 = px.line(daily_counts_45, x='FechaExpendiente', y='Ingresos', title="Ingresos Diarios (칔ltimos 45 D칤as)", markers=True)
    fig_daily_45.add_scatter(x=daily_counts_45['FechaExpendiente'], y=trend_days_45, mode='lines', line=dict(color='red', dash='dot'), name='Tendencia')
    fig_daily_45.add_scatter(x=future_dates_45, y=future_predictions_45[-7:], mode='lines+markers', line=dict(color='green', dash='dash'), name='Predicci칩n (Pr칩ximos 7 d칤as)')
    st.plotly_chart(fig_daily_45)
    
    # Explicaci칩n del Gr치fico
    st.write("""
    **Interpretaci칩n del Gr치fico:**
    - Este gr치fico muestra los ingresos diarios de expedientes en los 칰ltimos 45 d칤as.
    - La l칤nea roja punteada indica la tendencia general de los ingresos diarios.
    - La l칤nea verde discontinua proyecta los ingresos diarios para los pr칩ximos 7 d칤as.
    """)

    # Gr치fico 2: Pron칩stico de ingresos diarios con Prophet
    st.subheader("Pron칩stico de Ingresos Diarios")

    # Preparar los datos hist칩ricos completos para Prophet
    historical_data = data[['FechaExpendiente']].copy()
    historical_data['ds'] = historical_data['FechaExpendiente']
    daily_counts = historical_data.groupby(historical_data['ds'].dt.date).size().reset_index(name='y')
    daily_counts.rename(columns={'index': 'ds'}, inplace=True)
    daily_counts['ds'] = pd.to_datetime(daily_counts['ds'])  # Aseguramos el formato de fecha
    daily_counts = daily_counts[['ds', 'y']]  # Prophet requiere columnas ds (fecha) y y (valor)

    # Crear modelo Prophet
    model = Prophet(daily_seasonality=True, yearly_seasonality=True)
    model.fit(daily_counts)

    # Generar pron칩stico para los pr칩ximos 30 d칤as
    future_dates = model.make_future_dataframe(periods=30)
    forecast = model.predict(future_dates)

    # Graficar pron칩stico optimizado
    st.subheader("Pron칩stico de Ingresos Diarios (Optimizado para los Pr칩ximos 30 D칤as)")

    # Filtrar 칰ltimos 60 d칤as hist칩ricos + pr칩ximos 30 d칤as pronosticados
    forecast_focus = forecast[(forecast['ds'] >= (pd.Timestamp.now() - pd.DateOffset(days=60)))]

    fig_daily_optimized = px.line(
        forecast_focus, 
        x='ds', 
        y='yhat', 
        title="Pron칩stico de Ingresos Diarios (30 d칤as)", 
        labels={'ds': 'Fecha', 'yhat': 'Ingresos Estimados'}
    )

    # Resaltar la l칤nea central del pron칩stico
    fig_daily_optimized.add_scatter(
        x=forecast_focus['ds'], 
        y=forecast_focus['yhat'], 
        mode='lines', 
        line=dict(color='green', width=3), 
        name='Pron칩stico'
    )

    # L칤mites con menos opacidad
    fig_daily_optimized.add_scatter(
        x=forecast_focus['ds'], 
        y=forecast_focus['yhat_lower'], 
        mode='lines', 
        line=dict(color='blue', dash='dot', width=1), 
        name='L칤mite Inferior'
    )

    fig_daily_optimized.add_scatter(
        x=forecast_focus['ds'], 
        y=forecast_focus['yhat_upper'], 
        mode='lines', 
        line=dict(color='blue', dash='dot', width=1), 
        name='L칤mite Superior'
    )

    st.plotly_chart(fig_daily_optimized)

    # Explicaci칩n del Pron칩stico
    st.write("""
    **Interpretaci칩n del Pron칩stico:**
    - Este gr치fico muestra la tendencia diaria de los ingresos de expedientes basada en datos hist칩ricos desde 2018.
    - La l칤nea verde representa el pron칩stico central (promedio estimado) para los pr칩ximos 30 d칤as.
    - Las l칤neas azules punteadas indican los l칤mites de confianza superior e inferior, lo que significa que los valores reales podr칤an variar dentro de este rango.
    - Si la l칤nea de predicci칩n est치 subiendo, se espera un aumento en los ingresos diarios. Si est치 bajando, podr칤a haber una disminuci칩n.
    """)

    # Resumen Estad칤stico del Pron칩stico
    avg_prediction = forecast['yhat'][-30:].mean()
    st.write(f"""
    En promedio, se estima que el ingreso diario de expedientes para los pr칩ximos 30 d칤as ser치 de aproximadamente **{avg_prediction:.2f} expedientes por d칤a**.
    """)

# Pesta침a 3: Cierre de Expedientes
with tabs[2]:
    st.header("Cierre de Expedientes")
    st.info("Matriz de cierre de expedientes por evaluador en los 칰ltimos 15 d칤as.")

    # Asegurarnos de que 'FechaPre' est칠 en formato datetime
    data['FechaPre'] = pd.to_datetime(data['FechaPre'], errors='coerce')

    # Filtrar los 칰ltimos 15 d칤as
    last_15_days = pd.Timestamp.now() - pd.DateOffset(days=15)
    cierre_data = data[data['FechaPre'] >= last_15_days].copy()

    # Agrupar por evaluador y fecha de cierre
    cierre_matrix = cierre_data.groupby(['EVALASIGN', cierre_data['FechaPre'].dt.date]).size().unstack(fill_value=0)

    # Limitar a los 칰ltimos 15 d칤as
    cierre_matrix = cierre_matrix.loc[:, cierre_matrix.columns[-15:]]

    # Renombrar las columnas de fecha a formato dd/mm
    cierre_matrix.columns = [col.strftime('%d/%m') for col in cierre_matrix.columns]

    # Calcular tendencia (aumenta, disminuye, mantiene), ignorando ceros
    tendencias = {}
    for evaluador in cierre_matrix.index:
        series = cierre_matrix.loc[evaluador]
        # Filtrar valores diferentes de cero
        series_nonzero = series[series > 0]
        if series_nonzero.diff().sum() > 0:
            tendencia = "拘勇"
        elif series_nonzero.diff().sum() < 0:
            tendencia = "拘勇"
        else:
            tendencia = "俱뫮잺"
        tendencias[evaluador] = tendencia

    # Agregar la tendencia al final de la matriz
    cierre_matrix['Tendencia'] = cierre_matrix.index.map(tendencias)

    # Calcular el promedio de cierre por evaluador
    cierre_matrix['Promedio'] = cierre_matrix.drop(columns=['Tendencia']).mean(axis=1)

    # Ordenar la matriz por promedio de mayor a menor
    cierre_matrix = cierre_matrix.sort_values(by='Promedio', ascending=False)

    # Mostrar la matriz en Streamlit
    st.subheader("Matriz de Cierre de Expedientes (칔ltimos 15 D칤as)")
    st.dataframe(cierre_matrix)

    st.write("""
    **Interpretaci칩n de la Tendencia:**
    - **拘勇**: El evaluador est치 cerrando m치s expedientes en comparaci칩n con d칤as anteriores (sin considerar d칤as con cero cierres).
    - **拘勇**: El evaluador est치 cerrando menos expedientes en comparaci칩n con d칤as anteriores.
    - **俱뫮잺**: El evaluador est치 manteniendo un ritmo constante de cierres.
    """)
